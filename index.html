<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Compositional Causal Reasoning Evaluation in Language Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/brain.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <script type="text/javascript"
  src="https://www.maths.nottingham.ac.uk/plp/pmadw/LaTeXMathML.js">
  </script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Compositional Causal Reasoning Evaluation in Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://jmaasch.github.io/" target="_blank">Jacqueline R. M. A. Maasch</a><sup>1</sup>,
              </span>
                <span class="author-block">
                  <a href="https://alihanhyk.github.io/" target="_blank">Alihan Hüyük</a><sup>2</sup>,
                </span>
                  <span class="author-block">
                    <a href="https://scholar.google.co.uk/citations?user=osgiI-AAAAAJ&hl=en" target="_blank">Xinnuo Xu</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.microsoft.com/en-us/research/people/adityan/?from=https://research.microsoft.com/~adityan&type=exact" target="_blank">Aditya V. Nori</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://javiergonzalezh.github.io/" target="_blank">Javier Gonzalez</a><sup>3</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Cornell Tech, <sup>2</sup>Harvard University, <sup>3</sup>Microsoft Research Cambridge
                    <br>ICML 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2503.04556" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                  </span>


                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2503.04556" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>PDF</span>
                  </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/jmaasch/ccr" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                  </span>

                  <!-- Hugging Face Paper link -->
                    <span class="link-block">
                    <a href="https://huggingface.co/papers/2503.04556" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      &#129303;
                    </span>
                    <span>Hugging Face Paper</span>
                  </a>
                  </span>

                  <!-- Hugging Face Dataset -->
                  <span class="link-block">
                    <a href="https://huggingface.co/datasets/jmaasch/compositional_causal_reasoning" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      &#129303;
                    </span>
                    <span>Hugging Face Dataset</span>
                  </a>
                  </span>


                    <!-- Supplementary PDF link 
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>
                  -->

                  
                

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
-->
<!-- End teaser video -->
 

<!-- Paper abstract -->
<section class="hero">
  <div class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"><ccr>CCR</ccr>.<gb>GB</gb>: A <gb>G</gb>enerative <gb>B</gb>enchmark for <ccr>C</ccr>ompositional <ccr>C</ccr>ausal <ccr>R</ccr>easoning Evaluation</h2>
        <div class="content has-text-justified">
          <p>
            Causal reasoning and compositional reasoning are 
            two core aspirations in AI. Measuring 
            these behaviors requires principled 
            evaluation methods. Our work considers both behaviors simultaneously, under the umbrella of <b>compositional causal reasoning (CCR)</b>: 
            the ability to infer how causal measures compose 
            and, equivalently, how causal quantities propagate 
            through graphs. The <b>CCR.GB</b> benchmark is designed to measure CCR at <b>all 
            three levels of Pearl's Causal Hierarchy</b>: (1) associational, (2) interventional, and (3) counterfactual.
          </p>
          <p style="text-align:center">
            <img style="vertical-align:middle" src='static/images/pch.png' width="70%" class="center">
            <br>
            <small>Pearl's Causal Hierarchy: observing factual realities, exerting actions to 
              induce interventional realities, and imagining alternate counterfactual realities 
              [<a href="https://dl.acm.org/doi/pdf/10.1145/3501714.3501743?casa_token=hJAJZQLNGbEAAAAA:exuQk37fuXGMkpOVJEKACgnupjkP-adDQGhv2YzfBN9MfoERkAcHQRDgT3myWfccfqucQd8h63Q"
               target="_blank">Bareinboim et al. 2022</a>]. Lower levels underdetermine higher levels. The counterfactual quantity $p(y'_{x'} \mid x,y)$ is known as the <i>probability of necessity</i>. CCR.GB uses a related quantity, the <i>probability of necessity and sufficiency</i>, to evaluate AI reasoning 
               [<a href="https://dl.acm.org/doi/pdf/10.1145/3501714.3501735?casa_token=OsspeywzK1sAAAAA:cvfvbzXlkXCGsE3UlCCqGDdFfX9vMcT9p6GA6KFn52iVCB74Re70V3jarMMyr17EAhQivPmyphA" target="_blank">Pearl 1999</a>].
                </small>
          </p>
          <br>
          <p>
            <b>CCR.GB</b> provides two artifacts:
            <ul style="line-height:1.75;list-style-type:'&#10022;&#xFE0E; ';">
              <li><hi>Random CCR task generator.</hi> Open source code for on-demand task generation according to user specifications (graphical complexity, task theme, etc.). 
                Find our task generators on <a href="https://github.com/jmaasch/ccr" target="_blank">GitHub</a>. We currently offer four themes for random task 
                generation: CandyParty, FluVaccine, FlowerGarden, and ClinicalNotes (the most complex prompt setup).</li>
              <li><hi>Pre-sampled benchmark dataset.</hi> A static dataset sampled from the task generator, as a starting point for community benchmarking. 
                Pre-sampled data can be found on <a href="https://huggingface.co/datasets/jmaasch/compositional_causal_reasoning"
                target="_blank">Hugging Face</a>. Currently, pre-sampled data are available for the <b>ClinicalNotes theme on simple causal graphs</b>, 
                but we encourage users to increase the graphical complexity of the tasks they randomly sample. 
              </li>
            </ul>
            <b>Quick start:</b> See this <a href="https://github.com/jmaasch/ccr/blob/main/demos/demo_clinical_notes.ipynb"
            target="_blank">Jupyter Notebook demo</a> for a quick start on how to use our static dataset and task generators for evaluation, 
            including <b>recommended performance metrics</b>. Additional helpful code can be found in our <a href="https://github.com/jmaasch/ccr"
            target="_blank">GitHub repository</a>. 
            <br><br>

            Below, we cover the following topics.
            <ol>
              <li>Compositionality + causality</li>
              <li>Disentangling signal from noise in causal reasoning evaluation</li>
              <li>CCR task generation</li>
              <li>LMs as counterfactual data simulators</li>
              <li>Preliminary results</li>
              <li>Paper slides</li>
              <li>BibTeX</li>
            </ol>  
            
          </p>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="hero">
  <div class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Compositionality + causality</h2>
        <div class="content has-text-justified">
          <p>
            We define CCR as the ability to correctly infer <ccr>(1)</ccr> how local causal measures
            compose into global causal measures and <gb>(2)</gb> how global
            causal measures decompose into local causal measures, in
            both factual and counterfactual worlds. By extension, this requires reasoning over the propagation
            of causal quantities through graphs. Thus, our framework also implicitly tests for graphical reasoning. 
            <br><br>

            To facilitate CCR evaluation, we introduce a framework for the exhaustive assessment of <b>compositional consistency</b>: correct inference that
            equivalent compositions are indeed equal. We measure compositional consistency with respect to ground truth (<b>external
            validity</b>) and concordance among the LM's responses (<b>internal consistency</b>).
            <br><br>

            While explicitly combining compositional and causal reasoning evaluation in LMs is new, the intersection of compositionality 
            and causality already enjoys a rich mathematical framework: the formalisms and methods of graphical modeling and causal 
            inference. A classic example of compositionality in causal inference is the decomposition of the total effect in linear structural causal models (SCMs).
            When causal functions are linear, the total causal effect decomposes as a sum of the natural direct effect and natural indirect effect. 
            A compositionally consistent causal reasoning agent should correctly infer that TE is equivalent to NDE + NIE:
            <br><br>
            
            <p align="center">
              <img src="static/images/te_decomp.png" alt="TE = NDE + NIE" width="30%" class="center"/>
            </p>
            <br><br>

            In the current iteration of <b>CCR.GB</b>, we devise CCR tasks that leverage a particular compositional form of the probability of necessity and 
            sufficiency (PNS; <a href="https://dl.acm.org/doi/pdf/10.1145/3501714.3501735?casa_token=OsspeywzK1sAAAAA:cvfvbzXlkXCGsE3UlCCqGDdFfX9vMcT9p6GA6KFn52iVCB74Re70V3jarMMyr17EAhQivPmyphA" target="_blank">Pearl 1999</a>).
            <br><br>

            <p align="center">
                <img src="https://jmaasch.github.io/ccr_benchmark/static/images/pns.png" width="550">
            </p>

            As shown in <a href="https://arxiv.org/abs/2503.04556" target="_blank">Maasch et al. 2025</a>, the PNS composes multiplicatively over the biconnected components of the causal DAG.
            <br><br>

            <p align="center">
                <img src="https://jmaasch.github.io/ccr_benchmark/static/images/pns_comp.png" width="350">
            </p>

            We exploit this property to construct reasoning tasks that require the LM to reason correctly over both local PNS values (e.g., $PNS_{AC}$) as well as their compositions. 
            In the future, we aim to expand <b>CCR.GB</b> to incorporate additional compositional formulae for popular causal estimands. 
          </p>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<!-- Procedure -->
<section class="hero">
  <div class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Disentangling signal from noise in causal reasoning evaluation</h2>
        <div class="content has-text-justified">
          Contemporary AI faces a persistent recall-reasoning gap. Closing this gap will require that genuine reasoning is rigorously differentiated from alternative phenomena, such as recall of previously seen information. <b>CCR.GB</b> is designed with this in mind.
          <p>
            <ul style="line-height:1.75;list-style-type:'&#10022;&#xFE0E; ';">
              <li><hi>A generative approach.</hi> The automated task generator allows users to randomly sample new CCR tasks, mitigating risks 
                that data contamination is boosting perceived reasoning performance. </li>
              <li><hi>Reasoning vs training data recall.</hi> Fictitious causal world models help prevent the conflation of recall and reasoning. Variables 
                have no real-world counterparts, ensuring that newly-sampled causal relations were never seen by the model during training.
              </li>
              <li><hi>Reasoning vs in-context recall.</hi> Compositional consistency evaluation helps disentangle in-context recall (e.g., extraction of 
                relations directly from the causal context) from reasoning (e.g., inferring distal relationships that were never directly stated in the causal context).
              </li>
              <li><hi>Causal reasoning vs numeracy.</hi> This benchmark contains both quantitative and qualitative CCR tasks (i.e., those requiring and 
                not requiring numerical understanding, such as ordering numbers by magnitude). If an LM does significantly better on qualitative tasks, 
                this might suggest that poor numeracy is one root of failure on quantitative CCR tasks. Currently, the ClinicalNotes and FlowerGarden themes 
                offer qualitative prompts.
              </li>
            </ul>
          </p>
          <p style="text-align:center">
            <img style="vertical-align:middle" src='static/images/recall.png' width="50%" class="center"><br>
            <small>Lower error rate seen on factual questions (recall) than counterfactual questions (reasoning) [<a href="https://arxiv.org/abs/2410.03767" target="_blank">Hüyük et al. 2025</a>].</small>
          </p>
        </div>
      </div>
    </div>
  </div>
</div>
</section>


<!-- Procedure -->
<section class="hero">
  <div class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">CCR task generation</h2>
        <div class="content has-text-justified">
          <p>
            <ul style="line-height:1.75;list-style-type:'&#10022;&#xFE0E; ';">
              <li><hi>Causal world model.</hi> First, we define a fictional world corresponding to a randomly generated causal graph. 
                This will be the causal world model for the LM to reason over. The structural causal model defining our fictitious world is 
                comprised of binary exogenous noise variables, binary endogenous variables, and causal functions (logical operators <i>and</i>, <i>or</i>).</li>
              <li><hi>Causal context prompt.</hi> Second, we construct a verbal description of the world model. This verbal description — our 
                “causal context prompt” — contains all pertinent details needed for the LM to infer the world model, as well as extraneous details not needed to solve the CCR task. 
                The causal context centers on a user defined theme (e.g., ClinicalNotes, CandyParty, FlowerGarden, FluVaccine, etc.).</li>
              <li><hi>Sampling.</hi> Third, we randomly sample exogenous variables and extraneous variables and compute true endogenous variable values. 
                Sampled values are then used to construct the "sample context" in natural language, which is concatenated to our causal context prompt. Each causal context will copied 
                many times, where each copy is paired with a new sample context.
              <li><hi>Factual query prompts.</hi> Next, we construct factual queries by treating the causal context + sample context as observational data. 
                All queries are phrased as yes/no questions. The factual query is then concatenated to a copy of the causal context + sample context. Responses to factual prompts
                can be used to compute $p(y \mid x)$ for binary cause $x$ and binary effect $y$. Thus, evaluation on factual queries alone tests reasoning at the <b>associational level</b> 
                of Pearl's Causal Hierarchy. Note that evaluation at the associational level is less powerful at distinguishing recall from reasoning than the higher levels 
                of the Causal Hierarchy. </li>
              <li><hi>Interventional query pairs.</hi> Finally, we construct paired interventional queries corresponding to interventions $do(X = True)$ and $do(X = False)$. 
                Each interventional query is individually concatenated to a copy of the causal context + sample context. 
                As with factual queries, all interventional queries are phrased as yes/no questions. Responses to interventional prompts are used to compute $p(y \mid do(X = True))$ 
                and $p(y \mid do(X = False))$. As matched pairs over the same sample context, these are also used to compute the PNS: $p(y \mid do(X = True)) - p(y \mid do(X = False))$.  
                Thus, evaluation on interventional prompts tests for reasoning at both the <b>interventional and counterfactual rungs</b> of Pearl's Causal Hierarchy.</li>
            </ul>
            <img style="vertical-align:middle" src='static/images/prompt.png' class="center" width="90%">
          </p>
        </div>
      </div>
    </div>
  </div>
</div>
</section>


<!-- Procedure -->
<section class="hero">
  <div class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">LMs as counterfactual data simulators</h2>
        <div class="content has-text-justified">
          <p>
            Instead of directly prompting the model to perform formal causal inference 
            (as in <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/631bb9434d718ea309af82566347d607-Paper-Conference.pdf" target="_blank">Jin et al. 2023</a>), 
            <b>CCR.GB</b> treats LMs as <i>counterfactual data simulators</i> 
            (as in <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/d5a1f97d2b922da92e880d13b7d2bf02-Paper-Conference.pdf" 
            target="_blank">Gonzalez and Nori 2024</a>, <a href="https://arxiv.org/abs/2410.03767" target="_blank">Hüyük et al. 2025</a>). Series of yes/no questions are submitted to the LM, 
            and the resulting binary response vectors are treated as samples from observational and interventional distributions. These binary response vectors are then 
            used to compute PNS estimates.
            <br><br>
            
            Responses generated using <b>CCR.GB</b> allow for reasoning evaluation at all three levels of Pearl's Causal Hierarchy.
            <p>
              <ul style="line-height:1.75;list-style-type:'&#10022;&#xFE0E; ';">
                <li><hi>Associational.</hi></li>
                  <ul style="line-height:1.75;list-style-type:'&mdash;&#xFE0E; ';">
                    <li><b>Metrics.</b> Classic metrics can be used to compare factual query response vectors to ground truth (e.g., F1, accuracy, precision, etc.). 
                      This can also be considered a measure of logical reasoning, as causal functions are logical operators. </li>
                  </ul>
                <li><hi>Interventional.</hi></li>
                  <ul style="line-height:1.75;list-style-type:'&mdash;&#xFE0E; ';">
                    <li><b>Metrics.</b> Classic metrics like F1 score can also be used to compare interventional response vectors to ground truth.</li>
                  </ul>
                <li><hi>Counterfactual.</hi></li>
                  <ul style="line-height:1.75;list-style-type:'&mdash;&#xFE0E; ';">
                    <li><b>Metrics.</b> To assess counterfactual reasoning, we can estimate the PNS from the paired interventional response vectors 
                      and compare these estimates to the ground truth PNS for each quantity of interest in our causal world model. 
                      Approximation errors can be measured as the user desires, though we use the relative absolute error (RAE). We compute the RAE for the <b>external validity</b> 
                      of PNS estimates (compared to ground truth) and for the <b>internal consistency</b> of PNS compositions. In the latter case, estimates for theoretically equivalent 
                      PNS compositions are compared to each other, not to ground truth. </li>
                  </ul>
              </ul>
            </p>
          </p>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<!-- Procedure -->
<section class="hero">
  <div class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Preliminary results</h2>
        <div class="content has-text-justified">
          <p>
            As proof of concept, <a href="https://arxiv.org/abs/2503.04556" target="_blank">Maasch et al. (2025)</a> demonstrate the design of CCR tasks for language models in the LLama, Phi, and GPT families. 
            On a simple math word problem, this framework revealed a range of taxonomically distinct error patterns. Additionally,
            CCR errors increased with the complexity of causal paths for all models except o1. Preliminary error analyses revealed several failure modes:

            <ul style="line-height:1.75;list-style-type:'&#10022;&#xFE0E; ';">
              <li>Failure to correctly extract causal relations.</li>
              <li>Incorrect logic despite correct causal relation extraction.</li>
              <li>Truncated reasoning processes.</li>
              <li>Poor numeracy.</li>
            </ul>

            Results validate the utility and correct implementation of our framework, where success can be achieved by a sufficiently capable LM (e.g., o1 on the simple toy task). We recommend that users 
            push the limits of the next wave of reasoning models by sampling increasingly complex causal DAGs from our task generator. 
            <br><br>

            See <a href="https://arxiv.org/abs/2503.04556" target="_blank">Maasch et al. 2025</a> for further discussions of preliminary results.
          </p>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="static/images/icml/relative_errors_long.png" alt="results" width="60%" class="center"/>
          <h2 class="subtitle has-text-centered">
           <small></small>
         </h2>
       </div>
       <div class="item">
        <img src="static/images/icml/errors_by_quantity.png" alt="results" width="70%" class="center"/>
        <h2 class="subtitle has-text-centered">
          <small></small>
        </h2>
      </div>
      <div class="item">
        <img src="static/images/icml/relative_error_mediators.jpg" alt="results" width="70%" class="center"/>
        <h2 class="subtitle has-text-centered">
         <small></small>
       </h2>
      </div>
      <div class="item">
        <img src="static/images/icml/error_analysis_gpt4o_pnsdy_counterfactual.png" alt="results" width="80%" class="center"/>
        <h2 class="subtitle has-text-centered">
         <small></small>
       </h2>
      </div>
      <div class="item">
        <img src="static/images/icml/error_analysis_gpt4o_pnsdy_factual.png" alt="results" width="80%" class="center"/>
        <h2 class="subtitle has-text-centered">
         <small></small>
       </h2>
      </div>
      <div class="item">
        <img src="static/images/icml/error_analysis_gpt4o_pnsxy_factual.png" alt="results" width="80%" class="center"/>
        <h2 class="subtitle has-text-centered">
         <small></small>
       </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Procedure -->
<section class="hero">
  <div class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Paper slides</h2>
      </div>
    </div>
  </div>
</div>
</section>

<!-- Paper poster -->
<section class="hero">
  <div class="hero-body">
    <div class="container">

      <p align="center">
      <iframe  src="https://jmaasch.github.io/data/ccr_slides.pdf" width="60%" height="550"></iframe>
      </p>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
      @inproceedings{maasch2025ccr,
        title={Compositional Causal Reasoning Evaluation in Language Models},
        author={Jacqueline Maasch and Alihan Hüyük and Xinnuo Xu and Aditya V. Nori and Javier Gonzalez},
        booktitle={Proceedings of the 42nd International Conference on Machine Learning (ICML)},
        url={https://arxiv.org/abs/2503.04556},
        year={2025}
      }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
